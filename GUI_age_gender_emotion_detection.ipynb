{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3d50e4f9-17a4-4072-ae82-01659dbe3535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7e380eb3-1668-41ba-b566-170e10efa99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your pre-trained models\n",
    "age_gender_model = tf.keras.models.load_model('Downloads/age_gender_detection_model.keras')\n",
    "emotion_model = tf.keras.models.load_model('Downloads/Emotion_detection_3.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d0870ccf-1051-42cd-8ca6-00d96d28f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features from audio\n",
    "#def extract_features(file_path):\n",
    " #   y, sr = librosa.load(file_path, sr=16000)\n",
    "  #  mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "   # mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    #return mfccs_scaled\n",
    "\n",
    "def extract_features(file_path):\n",
    "    y, sr = librosa.load(file_path, duration=3, offset=0.5)\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    #mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "60572dca-1502-4db3-a5d6-8ca90ae44c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features_1(file_path):\n",
    "    #file_path = os.path.join(\"/content/cv-valid-train\", file_path)\n",
    "    y, sr = librosa.load(file_path, sr=16000)\n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfccs_scaled = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_scaled\n",
    "\n",
    "# Apply feature extraction to all files\n",
    "#data['features'] = data['filename'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3af0a297-c5ff-4154-aa06-a69c8c664275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GUI setup\n",
    "root = tk.Tk()\n",
    "root.title(\"Audio Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "98fbebbc-c507-40e4-a88f-542e0dee6081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label to show the selected file\n",
    "file_label = tk.Label(root, text=\"No file selected\")\n",
    "file_label.pack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a237fb32-82c6-46b2-92da-52f5143ff678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to upload audio\n",
    "def upload_audio():\n",
    "    file_path = filedialog.askopenfilename(filetypes=[(\"Audio Files\", \"*.wav;*.mp3;*.flac\")])\n",
    "    if file_path:\n",
    "        file_label.config(text=f\"Selected file: {file_path}\")\n",
    "        global audio_file_path\n",
    "        audio_file_path = file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8e8c242f-2bca-487d-a35f-17ede5acb4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect age and gender\n",
    "def detect_age_gender():\n",
    "    features = extract_features_1(audio_file_path)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    features = np.expand_dims(features, axis=-1)\n",
    "    #prediction = age_gender_model.predict(features)\n",
    "    gender_pred, age_pred = age_gender_model.predict(features)\n",
    "    #age = age_pred[0][0]\n",
    "    if age_pred[0][0] < 2:\n",
    "      age = \"Teens\"\n",
    "    elif age_pred[0][0] < 3:\n",
    "      age = \"Twenties\"\n",
    "    elif age_pred[0][0] < 4:\n",
    "      age = \"Thirties\"\n",
    "    elif age_pred[0][0] < 5:\n",
    "      age = \"Fourties\"\n",
    "    elif age_pred[0][0] < 6:\n",
    "      age = \"Fifties\"\n",
    "    elif age_pred[0][0] < 7:\n",
    "      age = \"Sixties\"\n",
    "    elif age_pred[0][0] < 8:\n",
    "      age = \"Seventies\"\n",
    "    else:\n",
    "      age = \"Eighties\"\n",
    "    gender = \"Female\" if gender_pred[0][0] < 0.5 else \"Male\"\n",
    "    if gender == \"Female\":\n",
    "        result_label.config(text=\"Upload male voice\")\n",
    "    else:\n",
    "        result_label.config(text=f\"Age: {age}, Gender: {gender}\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e7c4a85b-a27c-4b20-996a-d9013e744198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect emotion\n",
    "\n",
    "def detect_emotion():\n",
    "    features = extract_features(audio_file_path)\n",
    "    features = np.expand_dims(features, axis=0)\n",
    "    prediction = emotion_model.predict(features)\n",
    "    #emotion = np.argmax(prediction)\n",
    "    #emotion_dict = {0: \"Happy\", 1: \"Sad\", 2: \"Neutral\"}  # Example emotion labels\n",
    "    #return emotion_dict[emotion]\n",
    "    emotion = prediction\n",
    "    emot = 'k'\n",
    "    emotion_1= np.round(emotion)\n",
    "    emotion_1.tolist()\n",
    "    if emotion_1.tolist() == [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]:\n",
    "        emot = \"Predicted Emotion: Angry\"\n",
    "         #print(f\"Predicted Emotion: Angry\")\n",
    "    elif emotion_1.tolist() == [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]]:\n",
    "         emot = \"Predicted Emotion: Disgust\"\n",
    "         #print(f\"Predicted Emotion: Disgust\")\n",
    "    elif emotion_1.tolist() == [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]]:\n",
    "         emot =  \"Predicted Emotion: Fear\"\n",
    "         #print(f\"Predicted Emotion: Fear\")\n",
    "    elif emotion_1.tolist() == [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]]:\n",
    "         emot =  \"Predicted Emotion: Happy\"\n",
    "         #print(f\"Predicted Emotion: Happy\")\n",
    "    elif emotion_1.tolist() == [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]]:\n",
    "         emot = \"Predicted Emotion: Neutral\"\n",
    "         #print(f\"Predicted Emotion: Neutral\")\n",
    "    elif emotion_1.tolist() == [[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]]:\n",
    "         emot =  \"Predicted Emotion: Pleasant Surprised\"\n",
    "         #print(f\"Predicted Emotion: Pleasant Surprised\")\n",
    "    elif emotion_1.tolist() == [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]:\n",
    "         emot =  \"Predicted Emotion: Sad\"\n",
    "        # print(f\"Predicted Emotion: Sad\")\n",
    "    emotion_btn.config(text=f\"Emotion: {emot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e17114c0-5a51-44f1-a67f-15c9d6c0f657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Buttons\n",
    "upload_btn = tk.Button(root, text=\"Upload Audio\", command=upload_audio)\n",
    "upload_btn.pack(pady=10)\n",
    "\n",
    "age_gender_btn = tk.Button(root, text=\"Detect Age and Gender\", command=detect_age_gender)\n",
    "age_gender_btn.pack(pady=10)\n",
    "\n",
    "emotion_btn = tk.Button(root, text=\"Detect Emotion\", command=detect_emotion)\n",
    "emotion_btn.pack(pady=10)\n",
    "\n",
    "# Label to show the result\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204dbf64-2e2c-42bc-9c85-9a215ba83786",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
